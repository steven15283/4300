{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKmHrmqED4Dg"
      },
      "source": [
        "https://www.overleaf.com/5126168723yhzsgwxnhhvf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHKgEtr11WTj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOa_yWTY1dXq",
        "outputId": "65a1983a-568b-4225-c5d3-21ab2676c54d"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/steven15283/4300/master/carData.csv\n",
        "data = pd.read_csv('carData.csv', delimiter= ',')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-27 04:07:15--  https://raw.githubusercontent.com/steven15283/4300/master/carData.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24250 (24K) [text/plain]\n",
            "Saving to: ‘carData.csv’\n",
            "\n",
            "\rcarData.csv           0%[                    ]       0  --.-KB/s               \rcarData.csv         100%[===================>]  23.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-27 04:07:16 (103 MB/s) - ‘carData.csv’ saved [24250/24250]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibfu9Wnc1lAp"
      },
      "source": [
        "dataset = np.genfromtxt('carData.csv', delimiter= ',', skip_header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hds-TqUhD54l"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmXnNFLxJcog",
        "outputId": "85e6d0a9-d459-4a53-c9e8-a6b84f41ebe2"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3. 3. 2. ... 0. 0. 0.]\n",
            " [3. 3. 2. ... 0. 1. 0.]\n",
            " [3. 3. 2. ... 0. 2. 0.]\n",
            " ...\n",
            " [0. 0. 5. ... 2. 0. 0.]\n",
            " [0. 0. 5. ... 2. 1. 2.]\n",
            " [0. 0. 5. ... 2. 2. 3.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q204W8Hge5o6"
      },
      "source": [
        "dataset[dataset[:, -1] > 0, -1] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0KVje5xJX7C",
        "outputId": "a187b4bb-e66f-4548-85a2-ecad30f3c8cf"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3. 3. 2. ... 0. 0. 0.]\n",
            " [3. 3. 2. ... 0. 1. 0.]\n",
            " [3. 3. 2. ... 0. 2. 0.]\n",
            " ...\n",
            " [0. 0. 5. ... 2. 0. 0.]\n",
            " [0. 0. 5. ... 2. 1. 1.]\n",
            " [0. 0. 5. ... 2. 2. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSN1bYKl15_D"
      },
      "source": [
        "X = dataset[:, :-1]\n",
        "Y = dataset[:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukn6VftRkmyM",
        "outputId": "90412240-9316-418e-f108-ac84998414fa"
      },
      "source": [
        "print(X.shape, Y.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1728, 6) (1728,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZx8tCJyD2sv",
        "outputId": "c5401781-c9ea-4ce5-ab8d-2f1423019928"
      },
      "source": [
        "print(Y)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "[[3. 3. 2. 2. 0. 0.]\n",
            " [3. 3. 2. 2. 0. 1.]\n",
            " [3. 3. 2. 2. 0. 2.]\n",
            " ...\n",
            " [0. 0. 5. 5. 2. 0.]\n",
            " [0. 0. 5. 5. 2. 1.]\n",
            " [0. 0. 5. 5. 2. 2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPSHjown55ag"
      },
      "source": [
        "plt.hist(dataset[:,0])\n",
        "plt.title(\"Histogram of price rating\")\n",
        "price_rating_mean = np.mean(dataset[:,0])\n",
        "price_rating_median = np.median(dataset[:,0])\n",
        "price_rating_max = np.max(dataset[:,0])\n",
        "price_rating_min = np.min(dataset[:,0])\n",
        "\n",
        "print(price_rating_mean, price_rating_median, price_rating_max, price_rating_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYc58cHz6CC5"
      },
      "source": [
        "plt.hist(dataset[:,1])\n",
        "plt.title(\"Histogram of maintenance rating\")\n",
        "maintenance_rating_mean = np.mean(dataset[:,1])\n",
        "maintenance_rating_median = np.median(dataset[:,1])\n",
        "maintenance_rating_max = np.max(dataset[:,1])\n",
        "maintenance_rating_min = np.min(dataset[:,1])\n",
        "\n",
        "print(maintenance_rating_mean, maintenance_rating_median, maintenance_rating_max, maintenance_rating_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYVyhRZd6FGR"
      },
      "source": [
        "plt.hist(dataset[:,2])\n",
        "plt.title(\"Histogram of how many doors\")\n",
        "door_mean = np.mean(dataset[:,2])\n",
        "door_median = np.median(dataset[:,2])\n",
        "door_max = np.max(dataset[:,2])\n",
        "door_min = np.min(dataset[:,2])\n",
        "\n",
        "print(door_mean, door_median, door_max, door_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynM1s8_V6JA4"
      },
      "source": [
        "plt.hist(dataset[:,3])\n",
        "plt.title(\"Histogram of how many people can fit\")\n",
        "passenger_number_mean = np.mean(dataset[:,3])\n",
        "passenger_number_median = np.median(dataset[:,3])\n",
        "passenger_number_max = np.max(dataset[:,3])\n",
        "passenger_number_min = np.min(dataset[:,3])\n",
        "\n",
        "print(passenger_number_mean, passenger_number_median, passenger_number_max, passenger_number_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KWy_ikm56NR"
      },
      "source": [
        "plt.hist(dataset[:,4])\n",
        "plt.title(\"Histogram of lug boot capacity rating\")\n",
        "lug_boot_capacity_rating_mean = np.mean(dataset[:,4])\n",
        "lug_boot_capacity_rating_median = np.median(dataset[:,4])\n",
        "lug_boot_capacity_rating_max = np.max(dataset[:,4])\n",
        "lug_boot_capacity_rating_min = np.min(dataset[:,4])\n",
        "\n",
        "print(lug_boot_capacity_rating_mean, lug_boot_capacity_rating_median, lug_boot_capacity_rating_max, lug_boot_capacity_rating_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cehb2RHL6Rng"
      },
      "source": [
        "plt.hist(dataset[:,5])\n",
        "plt.title(\"Histogram of safety rating\")\n",
        "safety_rating_mean = np.mean(dataset[:,5])\n",
        "safety_rating_median = np.median(dataset[:,5])\n",
        "safety_rating_max = np.max(dataset[:,5])\n",
        "safety_rating_min = np.min(dataset[:,5])\n",
        "\n",
        "print(safety_rating_mean, safety_rating_median, safety_rating_max, safety_rating_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjBP60wz6Va6"
      },
      "source": [
        "plt.hist(dataset[:,6])\n",
        "plt.title(\"acceptibility of car\")\n",
        "acceptibility_mean = np.mean(dataset[:,6])\n",
        "acceptibility_median = np.median(dataset[:,6])\n",
        "acceptibility_max = np.max(dataset[:,6])\n",
        "acceptibility_min = np.min(dataset[:,6])\n",
        "\n",
        "print(acceptibility_mean, acceptibility_median, acceptibility_max, acceptibility_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBgaypPR6Zau"
      },
      "source": [
        "data['value'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qF0ijSz6f0B"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = 1, activation='linear'))\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
        "model.fit(dataset[:,0], dataset[:, 1], epochs = 64, batch_size = 32, verbose =0)\n",
        "predictions = model.predict(dataset[:, 0])\n",
        "print(predictions[:5])\n",
        "actual_predictions = predictions * fixedAcidity_max\n",
        "print(actual_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N05yI3eibNEf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim = len(X[0, :]), activation= 'relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X,Y, epochs = 256, verbose = 1 )\n",
        "prediction = model.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL6mR4p7dKYL",
        "outputId": "8d2f0abc-9090-4d68-874e-a03b876ced4a"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.6583982e-12]\n",
            " [3.3380549e-09]\n",
            " [3.9373034e-09]\n",
            " ...\n",
            " [8.7935150e-02]\n",
            " [9.9123722e-01]\n",
            " [9.9970722e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DcrKVyKQ2iR",
        "outputId": "50a9f49b-4a84-4ff7-9076-4c14b6fd647e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(Y, prediction.round())\n",
        "precision = precision_score(Y, prediction.round())\n",
        "recall = recall_score(Y, prediction.round())\n",
        "f1score = f1_score(Y, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 95.78%\n",
            "Precision: 91.43%\n",
            "Recall: 94.79%\n",
            "F1-score: 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsI7zYNs04LL",
        "outputId": "0c56d7eb-4f4a-45f3-9702-47111a49a111"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 56        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 97\n",
            "Trainable params: 97\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS_qUGRvw4MU",
        "outputId": "10af23a7-b4a5-4865-d700-f06eb50f95be"
      },
      "source": [
        "print(prediction[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.6583982e-12]\n",
            " [3.3380549e-09]\n",
            " [3.9373034e-09]\n",
            " [1.3820542e-10]\n",
            " [8.7517993e-09]\n",
            " [1.8278348e-08]\n",
            " [7.1850690e-09]\n",
            " [2.2945695e-08]\n",
            " [8.9848278e-08]\n",
            " [4.4770654e-12]\n",
            " [3.5597125e-08]\n",
            " [4.0310049e-05]\n",
            " [2.5748270e-10]\n",
            " [2.0472439e-06]\n",
            " [1.1691395e-04]\n",
            " [1.4808215e-08]\n",
            " [1.0190397e-04]\n",
            " [3.3894181e-04]\n",
            " [1.7429390e-11]\n",
            " [6.3240520e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSB01QGyxIVp",
        "outputId": "75c693bc-435f-4a84-cdd7-2ad21d43bead"
      },
      "source": [
        "print(Y[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk5VOWaGyfvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4df4c7b-d9ba-4bac-d0fa-bc9ec9f3cc5d"
      },
      "source": [
        "len(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scv6LPBdBKOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550540fa-b67a-4cfd-9941-41a23441ec17"
      },
      "source": [
        "# Shuffle the datasets\n",
        "import random\n",
        "np.random.shuffle(dataset)\n",
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1728, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op8omxQgIMJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9a2e02-e2a0-49cc-f6ba-d764e6194028"
      },
      "source": [
        "index_30percent = int(0.3 * len(dataset[:, 0]))\n",
        "print(index_30percent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScOUSBMjBMJx"
      },
      "source": [
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = dataset[:index_30percent, :-1]\n",
        "YVALID = dataset[:index_30percent, -1]\n",
        "XTRAIN = dataset[index_30percent:, :-1]\n",
        "YTRAIN = dataset[index_30percent:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "ai24uEMBEgm9",
        "outputId": "1d09a490-f2c9-4bb2-a870-e2f89ea88bdc"
      },
      "source": [
        "plt.hist(XVALID)\n",
        "plt.hist(YVALID)\n",
        "plt.title(\"x/y validation\")\n",
        "plt.legend(['buying price', 'maintenance cost rating', 'number of doors', 'number of persons', 'lug boot size rating', 'safety rating'], loc='upper right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fae3ca4fb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "ARHzRrp_En0d",
        "outputId": "1c37eb20-69f1-4485-aa08-1c69aa618ddb"
      },
      "source": [
        "plt.hist(XTRAIN)\n",
        "plt.hist(YTRAIN)\n",
        "plt.title(\"x/y training\")\n",
        "plt.legend(['buying price', 'maintenance cost rating', 'number of doors', 'number of persons', 'lug boot size rating', 'safety rating'], loc='upper right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fae3ca6fe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar5DwQBkr3LG"
      },
      "source": [
        "#accuracy on the validation set linear\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'linear')) \n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "model.summary()\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/MAE)\n",
        "plt.plot(history.history['mae']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_mae']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.title(\"linear\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round(), average='weighted')\n",
        "recall = recall_score(YTRAIN, p_training.round(), average='weighted')\n",
        "f1score = f1_score(YTRAIN, p_training.round(), average='weighted')\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round(), average='weighted')\n",
        "recall = recall_score(YVALID, p_valid.round(), average='weighted')\n",
        "f1score = f1_score(YVALID, p_valid.round(), average='weighted')\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuhTBqvCFVSS"
      },
      "source": [
        "model = Sequential()\n",
        "# 4 neurons in the first layer\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"1 layer\")\n",
        "plt.show()\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYwacZuoFw4-"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(8, activation='relu'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"2 layer\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTXAZaDQGlxD"
      },
      "source": [
        "model = Sequential()\n",
        "# 4 neurons in the first layer\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"3 layer\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfOYgUpPHDXl"
      },
      "source": [
        "model = Sequential()\n",
        "# 4 neurons in the first layer\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(48, activation='relu'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"4 layer\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxrhxmd1DepT"
      },
      "source": [
        "#adding more layers\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(48, activation='relu'))\n",
        "model.add(Dense(96, activation='relu'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 256)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"more layers\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYpnyO4ZhAlR"
      },
      "source": [
        "#adding more layers\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(48, activation='relu'))\n",
        "model.add(Dense(96, activation='relu'))\n",
        "model.add(Dense(192, activation='relu'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 256)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"more layers\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo7KO_KThKWg"
      },
      "source": [
        "#adding more layers\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(48, activation='relu'))\n",
        "model.add(Dense(96, activation='relu'))\n",
        "model.add(Dense(192, activation='relu'))\n",
        "model.add(Dense(384, activation='relu'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 256)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"more layers\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxUsCdg4iM2a"
      },
      "source": [
        "#adding more layers\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(48, activation='relu'))\n",
        "model.add(Dense(96, activation='relu'))\n",
        "model.add(Dense(192, activation='relu'))\n",
        "model.add(Dense(384, activation='relu'))\n",
        "model.add(Dense(768, activation='relu'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 256)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"more layers\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01042RN76D0L"
      },
      "source": [
        "#overfitting\n",
        "model = Sequential()\n",
        "model.add(Dense(60, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(120, activation='relu'))\n",
        "model.add(Dense(240, activation='relu'))\n",
        "model.add(Dense(480, activation='relu'))\n",
        "model.add(Dense(960, activation='relu'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs = 256)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"overfitting\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy0iluffdoSv"
      },
      "source": [
        "#linear in all layers\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'linear')) \n",
        "model.add(Dense(12, activation='linear'))\n",
        "model.add(Dense(24, activation='linear'))\n",
        "model.add(Dense(48, activation='linear'))\n",
        "model.add(Dense(96, activation='linear'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "model.summary()\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/MAE)\n",
        "plt.plot(history.history['mae']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_mae']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.title(\"linear\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round(), average='weighted')\n",
        "recall = recall_score(YTRAIN, p_training.round(), average='weighted')\n",
        "f1score = f1_score(YTRAIN, p_training.round(), average='weighted')\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round(), average='weighted')\n",
        "recall = recall_score(YVALID, p_valid.round(), average='weighted')\n",
        "f1score = f1_score(YVALID, p_valid.round(), average='weighted')\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMs2Zu41f2TG"
      },
      "source": [
        "#linear in last layer\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'sigmoid')) \n",
        "model.add(Dense(12, activation='sigmoid'))\n",
        "model.add(Dense(24, activation='sigmoid'))\n",
        "model.add(Dense(48, activation='sigmoid'))\n",
        "model.add(Dense(96, activation='sigmoid'))\n",
        "# 1 neuron in the last layer\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "model.summary()\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/MAE)\n",
        "plt.plot(history.history['mae']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_mae']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.title(\"linear in last layer\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round(), average='weighted')\n",
        "recall = recall_score(YTRAIN, p_training.round(), average='weighted')\n",
        "f1score = f1_score(YTRAIN, p_training.round(), average='weighted')\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round(), average='weighted')\n",
        "recall = recall_score(YVALID, p_valid.round(), average='weighted')\n",
        "f1score = f1_score(YVALID, p_valid.round(), average='weighted')\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBZux84ayA74"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'sigmoid')) \n",
        "model.add(Dense(12, activation='sigmoid'))\n",
        "model.add(Dense(24, activation='sigmoid'))\n",
        "model.add(Dense(48, activation='sigmoid'))\n",
        "model.add(Dense(96, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"sigmoid layers\")\n",
        "plt.show()\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olrCf3lVpv4I"
      },
      "source": [
        "#sigmoid last layer\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim = len(XTRAIN[0, :]), activation = 'linear')) \n",
        "model.add(Dense(12, activation='linear'))\n",
        "model.add(Dense(24, activation='linear'))\n",
        "model.add(Dense(48, activation='linear'))\n",
        "model.add(Dense(96, activation='linear'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"sigmoid last layer\")\n",
        "plt.show()\n",
        "print(\"Training\")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YVALID, p_valid.round())\n",
        "precision = precision_score(YVALID, p_valid.round())\n",
        "recall = recall_score(YVALID, p_valid.round())\n",
        "f1score = f1_score(YVALID, p_valid.round())\n",
        "print(\"Validation\")\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAJCc8ib5i4t"
      },
      "source": [
        "model = Sequential()\n",
        "# 4 neurons in the first layer\n",
        "model.add(Dense(9999, input_dim = len(XTRAIN[0, :]), activation = 'relu')) \n",
        "model.add(Dense(9999, activation='relu'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XVALID)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"denselayers\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, p_training.round())\n",
        "precision = precision_score(YTRAIN, p_training.round())\n",
        "recall = recall_score(YTRAIN, p_training.round())\n",
        "f1score = f1_score(YTRAIN, p_training.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI2ipeM3Tmvz"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# File name must be in quotes\n",
        "callback_a = ModelCheckpoint(filepath = 'carData.csv', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "# The patience value can be 10, 20, 100, etc. depending on when your model starts to overfit\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs=256, batch_size=8, callbacks = [callback_a, callback_b])\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"10 patience\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_YbTTDPEptH"
      },
      "source": [
        "callback_a = ModelCheckpoint(filepath = 'carData.csv', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "# The patience value can be 10, 20, 100, etc. depending on when your model starts to overfit\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs=256, batch_size=8, callbacks = [callback_a, callback_b])\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"20 patience\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3dyt6GLjxK4"
      },
      "source": [
        "callback_a = ModelCheckpoint(filepath = 'carData.csv', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "# The patience value can be 10, 20, 100, etc. depending on when your model starts to overfit\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=100, verbose=1)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs=256, batch_size=8, callbacks = [callback_a, callback_b])\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.title(\"100 patience\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QGcB561Bajc"
      },
      "source": [
        "dataset[dataset[:, -1] > 0, -1] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imKFfIGoBcaR"
      },
      "source": [
        "X = dataset[:, :-1]\n",
        "Y = dataset[:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LQHosn1hDOl",
        "outputId": "e3bdeefb-7990-4907-ed2a-f4caa76f8679"
      },
      "source": [
        "print(X.shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1728, 6) (1728,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQL9fu5BiYX",
        "outputId": "b3bb4dd7-80be-4c61-827a-c5fd0f1e2d79"
      },
      "source": [
        "index_30percent = int(0.3 * len(dataset[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = dataset[:index_30percent, :-1]\n",
        "YVALID = dataset[:index_30percent, -1]\n",
        "XTRAIN = dataset[index_30percent:, :-1]\n",
        "YTRAIN = dataset[index_30percent:, -1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BouP3lexbd7",
        "outputId": "df3a6b8a-181a-4934-c954-62efb51062dd"
      },
      "source": [
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(518, 6)\n",
            "(518,)\n",
            "(1210, 6)\n",
            "(1210,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P-CdSUuVI9R"
      },
      "source": [
        "my_new_xt = XTRAIN[:, 0]\n",
        "my_new_xv = XVALID[:, 0]\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = 1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(my_new_xt, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(my_new_xt)\n",
        "accuracyt = model.evaluate(my_new_xt, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(my_new_xv)\n",
        "accuracyv = model.evaluate(my_new_xv, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(my_new_xt, YTRAIN, validation_data = (my_new_xv, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(my_new_xt)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy1 = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy1 * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIGzdAGxj1JA"
      },
      "source": [
        "my_new_xt = XTRAIN[:, 1]\n",
        "my_new_xv = XVALID[:, 1]\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = 1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(my_new_xt, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(my_new_xt)\n",
        "accuracyt = model.evaluate(my_new_xt, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(my_new_xt)\n",
        "accuracyv = model.evaluate(my_new_xv, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(my_new_xt, YTRAIN, validation_data = (my_new_xv, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(my_new_xt)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy2 = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy2 * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri-EDswAkAW0"
      },
      "source": [
        "my_new_xt = XTRAIN[:, 2]\n",
        "my_new_xv = XVALID[:, 2]\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = 1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(my_new_xt, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(my_new_xt)\n",
        "accuracyt = model.evaluate(my_new_xt, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(my_new_xt)\n",
        "accuracyv = model.evaluate(my_new_xv, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(my_new_xt, YTRAIN, validation_data = (my_new_xv, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(my_new_xt)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy3 = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy3 * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spTRHqoMkCOz"
      },
      "source": [
        "my_new_xt = XTRAIN[:, 3]\n",
        "my_new_xv = XVALID[:, 3]\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = 1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(my_new_xt, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(my_new_xt)\n",
        "accuracyt = model.evaluate(my_new_xt, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(my_new_xt)\n",
        "accuracyv = model.evaluate(my_new_xv, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(my_new_xt, YTRAIN, validation_data = (my_new_xv, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(my_new_xt)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy4 = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy4 * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u3mP4lTkDjp"
      },
      "source": [
        "my_new_xt = XTRAIN[:, 4]\n",
        "my_new_xv = XVALID[:, 4]\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = 1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(my_new_xt, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(my_new_xt)\n",
        "accuracyt = model.evaluate(my_new_xt, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(my_new_xt)\n",
        "accuracyv = model.evaluate(my_new_xv, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(my_new_xt, YTRAIN, validation_data = (my_new_xv, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(my_new_xt)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy5 = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy5 * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1VIW7ZokFJM"
      },
      "source": [
        "my_new_xt = XTRAIN[:, 5]\n",
        "my_new_xv = XVALID[:, 5]\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = 1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(my_new_xt, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(my_new_xt)\n",
        "accuracyt = model.evaluate(my_new_xt, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(my_new_xt)\n",
        "accuracyv = model.evaluate(my_new_xv, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(my_new_xt, YTRAIN, validation_data = (my_new_xv, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(my_new_xt)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy6 = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy6 * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn-hZyl6sHe_"
      },
      "source": [
        "data = {'buying price':accuracy1, 'maintenance':accuracy2, 'doors':accuracy3,'persons':accuracy4,'lug_boot':accuracy5,'safety':accuracy6}\n",
        "input_data = list(data.keys())\n",
        "accuracy_value = list(data.values())\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "plt.bar(input_data, accuracy_value, color ='red', width = 0.4)\n",
        "plt.xlabel(\"input data feature\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"input data feature accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PUkNBoAj8OO"
      },
      "source": [
        "index_30percent = int(0.3 * len(dataset[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = dataset[:index_30percent, :-1]\n",
        "YVALID = dataset[:index_30percent, -1]\n",
        "XTRAIN = dataset[index_30percent:, :-1]\n",
        "YTRAIN = dataset[index_30percent:, -1]\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdjXTC1HGK3U"
      },
      "source": [
        "del_input = np.delete(dataset,0,1)#delete first column\n",
        "index_30percent = int(0.3 * len(del_input[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input[:index_30percent, :-1]\n",
        "YVALID = del_input[:index_30percent, -1]\n",
        "XTRAIN = del_input[index_30percent:, :-1]\n",
        "YTRAIN = del_input[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb2vQNhXGk-L"
      },
      "source": [
        "del_input = np.delete(dataset,1,1)#delete second column\n",
        "index_30percent = int(0.3 * len(del_input[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input[:index_30percent, :-1]\n",
        "YVALID = del_input[:index_30percent, -1]\n",
        "XTRAIN = del_input[index_30percent:, :-1]\n",
        "YTRAIN = del_input[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBI9YlY5ifwi"
      },
      "source": [
        "del_input = np.delete(dataset,2,1)#delete third column\n",
        "index_30percent = int(0.3 * len(del_input[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input[:index_30percent, :-1]\n",
        "YVALID = del_input[:index_30percent, -1]\n",
        "XTRAIN = del_input[index_30percent:, :-1]\n",
        "YTRAIN = del_input[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCFATdVdih6o"
      },
      "source": [
        "del_input = np.delete(dataset,3,1)#delete fourth column\n",
        "index_30percent = int(0.3 * len(del_input[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input[:index_30percent, :-1]\n",
        "YVALID = del_input[:index_30percent, -1]\n",
        "XTRAIN = del_input[index_30percent:, :-1]\n",
        "YTRAIN = del_input[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmtiIxCAipD4"
      },
      "source": [
        "del_input = np.delete(dataset,4,1)#delete fith column\n",
        "index_30percent = int(0.3 * len(del_input[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input[:index_30percent, :-1]\n",
        "YVALID = del_input[:index_30percent, -1]\n",
        "XTRAIN = del_input[index_30percent:, :-1]\n",
        "YTRAIN = del_input[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjGgwRSVitBT"
      },
      "source": [
        "del_input = np.delete(dataset,5,1)#delete sixth column\n",
        "index_30percent = int(0.3 * len(del_input[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input[:index_30percent, :-1]\n",
        "YVALID = del_input[:index_30percent, -1]\n",
        "XTRAIN = del_input[index_30percent:, :-1]\n",
        "YTRAIN = del_input[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ-64Kd92BQT"
      },
      "source": [
        "del_input = np.delete(dataset,0,1)#delete first column\n",
        "index_30percent = int(0.3 * len(del_input[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input[:index_30percent, :-1]\n",
        "YVALID = del_input[:index_30percent, -1]\n",
        "XTRAIN = del_input[index_30percent:, :-1]\n",
        "YTRAIN = del_input[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3NxmwcV2OTZ"
      },
      "source": [
        "del_input = np.delete(dataset,0,1)#delete first column\n",
        "del_input12 = np.delete(del_input,0,1)#delete second column which is the first column using dataset del_input\n",
        "index_30percent = int(0.3 * len(del_input12[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input12[:index_30percent, :-1]\n",
        "YVALID = del_input12[:index_30percent, -1]\n",
        "XTRAIN = del_input12[index_30percent:, :-1]\n",
        "YTRAIN = del_input12[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEqTdXJt2yDS"
      },
      "source": [
        "del_input = np.delete(dataset,0,1)#delete first column\n",
        "del_input12 = np.delete(del_input,0,1)#delete second column which is the first column using dataset del_input\n",
        "del_input123 = np.delete(del_input,0,1)#delete third column which is the first column using dataset del_input12\n",
        "index_30percent = int(0.3 * len(del_input123[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input123[:index_30percent, :-1]\n",
        "YVALID = del_input123[:index_30percent, -1]\n",
        "XTRAIN = del_input123[index_30percent:, :-1]\n",
        "YTRAIN = del_input123[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhPd6I133a-j"
      },
      "source": [
        "del_input = np.delete(dataset,0,1)#delete first column\n",
        "del_input12 = np.delete(del_input,0,1)#delete second column which is the first column using dataset del_input\n",
        "del_input123 = np.delete(del_input,0,1)#delete third column which is the first column using dataset del_input12\n",
        "del_input1235 = np.delete(del_input,1,1)#delete fifth column which is the second column using dataset del_input123\n",
        "index_30percent = int(0.3 * len(del_input1235[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input1235[:index_30percent, :-1]\n",
        "YVALID = del_input1235[:index_30percent, -1]\n",
        "XTRAIN = del_input1235[index_30percent:, :-1]\n",
        "YTRAIN = del_input1235[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GA1noRU4G7X"
      },
      "source": [
        "del_input = np.delete(dataset,0,1)#delete first column\n",
        "del_input12 = np.delete(del_input,0,1)#delete second column which is the first column using dataset del_input\n",
        "del_input123 = np.delete(del_input,0,1)#delete third column which is the first column using dataset del_input12\n",
        "del_input1235 = np.delete(del_input,1,1)#delete fifth column which is the second column using dataset del_input123\n",
        "del_input12354 = np.delete(del_input,0,1)#delete fourth column which is the first column using dataset del_input1235\n",
        "index_30percent = int(0.3 * len(del_input12354[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input12354[:index_30percent, :-1]\n",
        "YVALID = del_input12354[:index_30percent, -1]\n",
        "XTRAIN = del_input12354[index_30percent:, :-1]\n",
        "YTRAIN = del_input12354[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFmq7KOk4X1N"
      },
      "source": [
        "del_input = np.delete(dataset,0,1)#delete first column\n",
        "del_input12 = np.delete(del_input,0,1)#delete second column which is the first column using dataset del_input\n",
        "del_input123 = np.delete(del_input,0,1)#delete third column which is the first column using dataset del_input12\n",
        "del_input1235 = np.delete(del_input,1,1)#delete fifth column which is the second column using dataset del_input123\n",
        "del_input12354 = np.delete(del_input,0,1)#delete fourth column which is the first column using dataset del_input1235\n",
        "del_input123546 = np.delete(del_input,0,1)#delete sixth column which is the first column using dataset del_input12354\n",
        "index_30percent = int(0.3 * len(del_input123546[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation, 30% validation set and 70% training \n",
        "XVALID = del_input123546[:index_30percent, :-1]\n",
        "YVALID = del_input123546[:index_30percent, -1]\n",
        "XTRAIN = del_input123546[index_30percent:, :-1]\n",
        "YTRAIN = del_input123546[index_30percent:, -1]\n",
        "print(XVALID.shape)\n",
        "print(YVALID.shape)\n",
        "print(XTRAIN.shape)\n",
        "print(YTRAIN.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim = len(XTRAIN[0, :]), activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Learn the model from training set\n",
        "model.fit(XTRAIN, YTRAIN)\n",
        "# Evaluate on the training set (should deliver high accuracy)\n",
        "p_training = model.predict(XTRAIN)\n",
        "accuracyt = model.evaluate(XTRAIN, YTRAIN)\n",
        "#Evaluate on the validation set\n",
        "p_valid = model.predict(XTRAIN)\n",
        "accuracyv = model.evaluate(XVALID, YVALID)\n",
        "print(accuracyv)\n",
        "print(accuracyt)\n",
        "# Do the training (specify the validation set as well)\n",
        "history = model.fit(XTRAIN, YTRAIN, validation_data = (XVALID, YVALID), verbose = 1, epochs  = 256)\n",
        "prediction = model.predict(XTRAIN)\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(YTRAIN, prediction.round())\n",
        "precision = precision_score(YTRAIN, prediction.round())\n",
        "recall = recall_score(YTRAIN, prediction.round())\n",
        "f1score = f1_score(YTRAIN, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}